Wednesday, 16 July 2014
========================

The database is getting massive. It looks like much of the size is based on the interesting decision to have full photos directly in the database itself. Let's move those to the file server (maybe a spot on the media server).

First thing, I need to cut things into smaller pieces. This fails, giving me an out of memory issue:

```php
    $staff = Staff::all();

    foreach($staff as $person) {
        echo '<p>'.$person->name.'</p>';
    }
```

This is better, and returns the whole list in a few seconds:

```php
    $this->staff->chunk(50, function($people){
        foreach($people as $person)
            echo '<p>'.$person->name.'</p>';
    });
```

If we are to copy the photos, and resize them, it'll take a while for each one. Is there any way to send partial data to the client, showing the progress?

It might need to spawn a sub-process? Return something right away, then continue with that? Can we send output in pieces to a client?

Theoretically, that's what queues and workers are for... But, honestly, I don't need it to be a background process, I just want to return a partial page as it's being constructed.

I found a solution. It's based on information at 
http://inchoo.net/tools-frameworks/chunked-transfer-encoding/

```php
    public function copyAll()
    {
        $response = \Response::make('', 200, [
            'Content-Encoding' => 'chunked',
            'Transfer-Encoding' => 'chunked',
            'Content-Type' => 'text/html',
            'Connection' => 'keep-alive',
        ]);
        $response->sendHeaders();

        flush();
        ob_flush();

        $this->staff->chunk(10, function($people){
            foreach($people as $person) {
                $this->dump_chunk('<p>'.$person->name.'</p>');
                flush();
                ob_flush();
            }
        });
    }

    private function dump_chunk($chunk) 
    {
       echo $chunk;
       echo "\r\n";
    }
```

The bigger the chunk, the faster it is (at least for this very simple test). On my machine, a chunk of 10 took 26.6 seconds to complete. 50 took 5.5 seconds. But it's also not processing anything significant at this time. Smaller chunks will return data to the user faster.



Friday, 18 July 2014
====================

Doh! I just found out that I didn't update node or npm on my staging machine. I'd really like to get those working, now, so that I can check stuff before pushing out a bunch of big changes. How did I install/update node and npm?

    sudo add-apt-repository ppa:chris-lea/node.js  
    sudo apt-get update  
    sudo apt-get install nodejs

NOTE: If your system does not have add-apt-repository, it can be installed like so:

    sudo apt-get install python-software-properties

This installs both nodejs and npm.

    npm install

Everything looks like it's there...

    npm install bower
    npm install gulp

Not running... On my main system, files for gulp and bower are outside of the project, in a separate folder. How can I do that? Hmmm....

    sudo npm install -g bower
    sudo npm install -g gulp

That worked.

    bower install
    gulp update

...and I'm good to go.

... except that my machine is complaining that fileinfo is not found...

    edit `C:\wamp\bin\php\php5.4.3\php.ini`   to remove the comment before `extension=php_fileinfo.dll`

... and we're good.

