Wednesday, 16 July 2014
========================

The database is getting massive. It looks like much of the size is based on the interesting decision to have full photos directly in the database itself. Let's move those to the file server (maybe a spot on the media server).

First thing, I need to cut things into smaller pieces. This fails, giving me an out of memory issue:

```php
    $staff = Staff::all();

    foreach($staff as $person) {
        echo '<p>'.$person->name.'</p>';
    }
```

This is better, and returns the whole list in a few seconds:

```php
    $this->staff->chunk(50, function($people){
        foreach($people as $person)
            echo '<p>'.$person->name.'</p>';
    });
```

If we are to copy the photos, and resize them, it'll take a while for each one. Is there any way to send partial data to the client, showing the progress?

It might need to spawn a sub-process? Return something right away, then continue with that? Can we send output in pieces to a client?

Theoretically, that's what queues and workers are for... But, honestly, I don't need it to be a background process, I just want to return a partial page as it's being constructed.

I found a solution. It's based on information at 
http://inchoo.net/tools-frameworks/chunked-transfer-encoding/

```php
    public function copyAll()
    {
        $response = \Response::make('', 200, [
            'Content-Encoding' => 'chunked',
            'Transfer-Encoding' => 'chunked',
            'Content-Type' => 'text/html',
            'Connection' => 'keep-alive',
        ]);
        $response->sendHeaders();

        flush();
        ob_flush();

        $this->staff->chunk(10, function($people){
            foreach($people as $person) {
                $this->dump_chunk('<p>'.$person->name.'</p>');
                flush();
                ob_flush();
            }
        });
    }

    private function dump_chunk($chunk) 
    {
       echo $chunk;
       echo "\r\n";
    }
```

The bigger the chunk, the faster it is (at least for this very simple test). On my machine, a chunk of 10 took 26.6 seconds to complete. 50 took 5.5 seconds. But it's also not processing anything significant at this time. Smaller chunks will return data to the user faster.

