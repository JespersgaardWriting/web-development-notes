Thursday, 4 September 2014
===========================

We have an issue with corrupted characters in the database. It looks like there's a problem with the character collation. Tables have been using latin1_swedish_ci, but the backups (and new code) are all using utf8_general_ci. This has been an issue for a long, long time. Let's see if we can fix it today.

First, let's get a scope of the problem. To see non-ascii characters for a given table and field, we can use:

    SELECT count(*) 
    FROM `table`
    WHERE NOT HEX(`field`) REGEXP '^([0-7][0-9A-F])*$'

We can run this on every field in every table...

```php
    public function getScrambledCharacters()
    {
        $this->forAllStringFieldsInAllTables(function($table, $field)
        {
            $fieldName = $field->getName();

            $data = DB::table($table)
                ->whereRaw("NOT HEX(`{$fieldName}`) REGEXP '^([0-7][0-9A-F])*$'")
                ->get([$fieldName]);

            if (count($data)) {
                echo "<h1>$table.$fieldName</h1>";
                foreach($data as $item) {
                    echo "<p>{$item->$fieldName}</p>";
                }
            }
        });
    }

    private function forAllStringFieldsInAllTables($callback)
    {
        set_time_limit(120);
        $schemaManager = DB::connection()->getDoctrineSchemaManager();
        $tables = $schemaManager->listTableNames();
        $return = [];
        foreach ($tables as $table) 
        {
            $fields = $schemaManager->listTableColumns($table);

            foreach ($fields as $field) {
                $type = (string) $field->getType();
                if (strpos('String|Text', $type) !== False) {
                    $return[] = $callback($table, $field);
                }
            }
        }

        return $return;
    }
```

From just looking at the data, I can see that I have a lot of duplicates. For instance, I have 871 matches of the string:

    ?âãÆ?åÔÇÖ?âÔÇá?óÔé¼Ôäó?âãÆ?óÔé¼?í?âÔÇÜ?é?ó?âãÆ?åÔÇÖ?âÔÇÜ?é?ó?âãÆ?é?ó?â?ó?óÔé¼?í?é?¼?âÔÇª?é?í?âãÆ?óÔé¼?í?âÔÇÜ?é?¼?âãÆ?åÔÇÖ?â?ó?óÔÇÜ?¼?à?í?âãÆ?óÔé¼?í?âÔÇÜ?é?ª

That same string is found in:

    facility_reservations.notes
    gift_shop_vendors.notes
    guest_notes.note
    reservations.notes
    spa_reservations.notes
    staff.confidential_notes
    staff.medical_information
    staff_time_sheet.notes
    vehicle_adventure_passengers.notes
    vehicle_adventure_reservations.notes

We should be able to handle it with a search and replace...

    update table set field = replace(field, 'foo', 'bar') where instr(field, 'foo') > 0;

So...

    update facility_reservations 
    set notes = replace(notes, '?âãÆ?åÔÇÖ?âÔÇá?óÔé¼Ôäó?âãÆ?óÔé¼?í?âÔÇÜ?é?ó?âãÆ?åÔÇÖ?âÔÇÜ?é?ó?âãÆ?é?ó?â?ó?óÔé¼?í?é?¼?âÔÇª?é?í?âãÆ?óÔé¼?í?âÔÇÜ?é?¼?âãÆ?åÔÇÖ?â?ó?óÔÇÜ?¼?à?í?âãÆ?óÔé¼?í?âÔÇÜ?é?ª', ' - ') 
    where instr(notes, '?âãÆ?åÔÇÖ?âÔÇá?óÔé¼Ôäó?âãÆ?óÔé¼?í?âÔÇÜ?é?ó?âãÆ?åÔÇÖ?âÔÇÜ?é?ó?âãÆ?é?ó?â?ó?óÔé¼?í?é?¼?âÔÇª?é?í?âãÆ?óÔé¼?í?âÔÇÜ?é?¼?âãÆ?åÔÇÖ?â?ó?óÔÇÜ?¼?à?í?âãÆ?óÔé¼?í?âÔÇÜ?é?ª') > 0;

(...and all of the other affected tables)

Leaving me with 4483 affected records.

 